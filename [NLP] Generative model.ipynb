{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/masdevas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "import scrapy.crawler as crawler\n",
    "from scrapy.utils.log import configure_logging\n",
    "from multiprocessing import Process, Queue\n",
    "from twisted.internet import reactor\n",
    "from collections import Counter\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2LMHeadModel\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import BatchSampler, RandomSampler\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from lyricsgenius import Genius\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.ticker import FuncFormatter\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('nlp')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_data(function):\n",
    "    def f(q):\n",
    "        try:\n",
    "            json_data = function()\n",
    "            q.put(json.dumps(json_data))\n",
    "        except Exception as e:\n",
    "            q.put(e)\n",
    "    q = Queue()\n",
    "    p = Process(target=f, args=(q,))\n",
    "    p.start()\n",
    "    result = q.get()\n",
    "    p.join()\n",
    "    gc.collect()\n",
    "    try:\n",
    "        json_data = json.loads(result)\n",
    "    except:\n",
    "        raise result\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rap texts parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_genius_token():\n",
    "    with open('genius_token.txt', 'r') as f:\n",
    "        token = f.readline().strip()\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rap_data_extended():\n",
    "    genius = Genius(read_genius_token(), timeout=60)\n",
    "    storage = {}\n",
    "    try:\n",
    "        class RapExtendedSpider(scrapy.Spider):\n",
    "            name = \"rap_extended_checker\"\n",
    "            start_urls = [\n",
    "                'https://www.allmusic.com/style/gangsta-rap-ma0000002611/artists?1651103019828'\n",
    "            ]\n",
    "\n",
    "            def parse(self, response, depth=0):\n",
    "                resp = response.xpath(\"//div[@class='artist-highlight info-grid']//div[@class='artist']/text()\")\n",
    "                for item in resp:\n",
    "                    artist_name = item.get().strip()\n",
    "                    if len(artist_name) > 0:\n",
    "                        try:\n",
    "                            artist = genius.search_artist(artist_name, max_songs=150)\n",
    "                        except:\n",
    "                            continue\n",
    "                        storage[artist_name] = []\n",
    "                        for song in artist.songs:\n",
    "                            storage[artist_name].append(song.lyrics)\n",
    "                \n",
    "        runner = crawler.CrawlerRunner()\n",
    "        deferred = runner.crawl(RapExtendedSpider)\n",
    "        deferred.addBoth(lambda _: reactor.stop())\n",
    "        reactor.run()\n",
    "        return storage\n",
    "    except Exception as e:\n",
    "        return {'exception' : str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING\n"
     ]
    }
   ],
   "source": [
    "storage_file = 'storage.pkl'\n",
    "def is_rawdata_exist(storage_file):\n",
    "    return os.path.exists(storage_file)\n",
    "    # return False\n",
    "\n",
    "if is_rawdata_exist(storage_file):\n",
    "    print('LOADING')\n",
    "    with open(storage_file, 'rb') as f:\n",
    "        storage = pickle.load(f)\n",
    "else:\n",
    "    print('FROM WEB')\n",
    "    storage = {}  \n",
    "#     storage['usagov'] = get_web_data(get_usagov_rss_data)\n",
    "#     storage['joke'] = get_web_data(get_joke_rss_data)\n",
    "#     storage['rap'] = get_web_data(get_rap_data)\n",
    "    storage['rap'] = get_web_data(get_rap_data_extended)\n",
    "    with open(storage_file, 'wb') as f:\n",
    "        pickle.dump(storage, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess sentences for HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_to_process = copy.deepcopy(storage)\n",
    "\n",
    "map_labels = {'rap' : 0}\n",
    "\n",
    "words_limit = 22\n",
    "words_at_least = 10\n",
    "\n",
    "# def split_sentence_to_approproate_length(res_proc_item):\n",
    "#     sentences = []\n",
    "#     splitted = res_proc_item.split(' ')\n",
    "#     for idx in range(0, len(splitted), words_limit):\n",
    "#         part_of_words = splitted[idx:idx+words_limit]\n",
    "#         if len(part_of_words) < words_at_least:\n",
    "#             continue\n",
    "#         else:\n",
    "#             sentences.append(' '.join(part_of_words))\n",
    "#     return sentences\n",
    "\n",
    "stop_symbols = set(['...', '.', '?', '!', '!!!', '?!', '?!'])\n",
    "\n",
    "def join_rap_sentences(local_lines, lines_in_group):\n",
    "    rap_sentences = []\n",
    "    idx = 0\n",
    "    while idx < len(local_lines):\n",
    "        line = local_lines[idx].strip().lower()\n",
    "        if len(line) == 0:\n",
    "            del local_lines[idx]\n",
    "            continue\n",
    "        if idx + lines_in_group > len(local_lines):\n",
    "            res_proc_item = line\n",
    "        else:\n",
    "            second_line = local_lines[idx + 1].strip().lower()\n",
    "            if len(second_line) == 0:\n",
    "                del local_lines[idx + 1]\n",
    "                continue\n",
    "            res_proc_item = line + ' ' + second_line\n",
    "        res_proc_item = res_proc_item.replace(',', '')\n",
    "        splitted = res_proc_item.split(' ')[:words_limit]\n",
    "        if len(splitted) >= words_at_least:\n",
    "            joined = ' '.join(splitted)\n",
    "            end_empty = True\n",
    "            for token in stop_symbols:\n",
    "                if joined.endswith(token):\n",
    "                    end_empty = False\n",
    "                    break\n",
    "            if end_empty:\n",
    "                joined += '.'\n",
    "            \n",
    "            rap_sentences.append(joined)\n",
    "        idx += lines_in_group\n",
    "    return rap_sentences\n",
    "\n",
    "# TODO how to have a deal with slang?\n",
    "def get_approx_sentences_from_lyrics(lyrics, local_processed_data):\n",
    "    couplets = re.split('\\[.*\\]' ,lyrics)\n",
    "    for couplet in couplets:\n",
    "        local_lines = couplet.split('\\n')\n",
    "        \n",
    "        if len(local_lines) == 1:\n",
    "            continue\n",
    "        lines_in_group = 2\n",
    "        rap_sentences = join_rap_sentences(local_lines, lines_in_group)\n",
    "        local_processed_data.extend(rap_sentences)\n",
    "\n",
    "def get_data_lyrics(substorage, topic_key):\n",
    "    local_processed_data = []\n",
    "    for lyrics_list in substorage.values():\n",
    "        for lyrics in lyrics_list:\n",
    "            get_approx_sentences_from_lyrics(lyrics, local_processed_data)\n",
    "    local_processed_labels = [map_labels[topic_key]] * len(local_processed_data)\n",
    "    with open(f'tmp_{topic_key}.json', 'w') as f:\n",
    "        json.dump({'section' : local_processed_data}, f, indent=4, sort_keys=True)\n",
    "    return local_processed_data, local_processed_labels\n",
    "\n",
    "processed_data = []\n",
    "processed_labels = []\n",
    "for topic_key in map_labels.keys():\n",
    "    if topic_key == 'rap':\n",
    "        local_processed_data, local_processed_labels = get_data_lyrics(storage_to_process[topic_key], topic_key)\n",
    "        processed_data.extend(local_processed_data)\n",
    "        processed_labels.extend(local_processed_labels)\n",
    "    else:\n",
    "        raise Exception(f'Unknown topic_key: {topic_key}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_data = pd.DataFrame({'text' : processed_data, 'label' : processed_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am a nightmare walkin' psychopath talkin' ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>livin' life like a firecracker quick is my fus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red or blue cuz or blood it just don't matter ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the gangs of l.a. will never die - just multiply.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you see they hit us then we hit them then we h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138314</th>\n",
       "      <td>with they **** ***** attitudes why it's gotta ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138315</th>\n",
       "      <td>i don't owe you chick you wasn't with me when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138316</th>\n",
       "      <td>even if you was you wouldn't shoot the stick w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138317</th>\n",
       "      <td>know you a hatin lil **** always talking other...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138318</th>\n",
       "      <td>need to put a sock in it you speak facts alrig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138319 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0       i am a nightmare walkin' psychopath talkin' ki...      0\n",
       "1       livin' life like a firecracker quick is my fus...      0\n",
       "2       red or blue cuz or blood it just don't matter ...      0\n",
       "3       the gangs of l.a. will never die - just multiply.      0\n",
       "4       you see they hit us then we hit them then we h...      0\n",
       "...                                                   ...    ...\n",
       "138314  with they **** ***** attitudes why it's gotta ...      0\n",
       "138315  i don't owe you chick you wasn't with me when ...      0\n",
       "138316  even if you was you wouldn't shoot the stick w...      0\n",
       "138317  know you a hatin lil **** always talking other...      0\n",
       "138318  need to put a sock in it you speak facts alrig...      0\n",
       "\n",
       "[138319 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    19892\n",
       "18    12911\n",
       "17    12609\n",
       "16    12526\n",
       "19    11595\n",
       "15    11168\n",
       "20    10220\n",
       "14     9938\n",
       "13     8425\n",
       "21     8292\n",
       "12     7880\n",
       "11     6694\n",
       "10     6169\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_data['text'].apply(lambda x: len(x.split(' '))).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse common starts and continuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_subseqs(data, len_main_subseq, len_extra_subseq, count_main_seqs, count_extra_seqs):\n",
    "    set_main_seqs = {}\n",
    "    for line in data['text']:\n",
    "        splited_sentence = line[:-1].split(' ')\n",
    "        for word_idx in range(len(splited_sentence)):\n",
    "            if word_idx + len_main_subseq + len_extra_subseq > len(splited_sentence):\n",
    "                break\n",
    "            main_subseq = ' '.join(splited_sentence[word_idx:word_idx+len_main_subseq])\n",
    "            if main_subseq not in set_main_seqs.keys():\n",
    "                set_main_seqs[main_subseq] = 1\n",
    "            else:\n",
    "                set_main_seqs[main_subseq] += 1\n",
    "    sorted_main_seqs_counted = sorted(list(set_main_seqs.items()), key=lambda x: -x[1])\n",
    "    sorted_main_seqs = [sorted_main_seqs_counted[idx] for idx in range(count_main_seqs)]\n",
    "    \n",
    "    preresult = {key : [] for key in sorted_main_seqs}\n",
    "    for main_key, count in sorted_main_seqs:\n",
    "        splitted_main_key = main_key.split(' ')\n",
    "        for line in data['text']:\n",
    "            splited_sentence = line[:-1].split(' ')\n",
    "            for word_idx in range(len(splited_sentence)):\n",
    "                if word_idx + len_main_subseq + len_extra_subseq > len(splited_sentence):\n",
    "                    break\n",
    "                is_main_eq = True\n",
    "                for main_word, extra_word in zip(splitted_main_key, splited_sentence[word_idx:word_idx+len_main_subseq]):\n",
    "                    if main_word != extra_word:\n",
    "                        is_main_eq = False\n",
    "                        break\n",
    "                if not is_main_eq:\n",
    "                    continue\n",
    "                extra_subseq = ' '.join(splited_sentence[word_idx+len_main_subseq:word_idx+len_main_subseq+len_extra_subseq])\n",
    "                preresult[(main_key, count)].append(extra_subseq)\n",
    "    \n",
    "    result = {key : [] for key in sorted_main_seqs}\n",
    "    for key, collection in preresult.items():\n",
    "        common_extras = Counter(collection).most_common(count_extra_seqs)\n",
    "        result[key] = common_extras\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('in the', 11599): [('hood', 424),\n",
       "  ('back', 404),\n",
       "  ('house', 399),\n",
       "  ('air', 298),\n",
       "  ('game', 296)],\n",
       " ('on the', 6422): [('block', 280),\n",
       "  ('streets', 192),\n",
       "  ('floor', 156),\n",
       "  ('mic', 136),\n",
       "  ('corner', 125)],\n",
       " ('to the', 5550): [('top', 101),\n",
       "  ('beat', 96),\n",
       "  ('game', 74),\n",
       "  ('west', 72),\n",
       "  ('side', 67)],\n",
       " ('i got', 4540): [('a', 753),\n",
       "  ('the', 477),\n",
       "  ('my', 381),\n",
       "  ('to', 249),\n",
       "  ('it', 169)],\n",
       " ('you know', 4513): [('what', 693),\n",
       "  ('i', 464),\n",
       "  ('the', 332),\n",
       "  ('how', 258),\n",
       "  ('that', 227)]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_subseqs(df_text_data, 2, 1, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>but this year i went down to miami and got my ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>or a cop shot your kid in the back yard shit w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>yo ernie c take these motherfuckers home yeah ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>you gotta get your cash right to get in the ga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>in the house boy i got my one and only afrika ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138192</th>\n",
       "      <td>i'm heavy in the hood 'cause i got that weight...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138193</th>\n",
       "      <td>i'm heavy in the hood 'cause i got that weight...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138194</th>\n",
       "      <td>(what up elder?) i'm heavy in the hood 'cause ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138196</th>\n",
       "      <td>(they already know they can't keep up with you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138197</th>\n",
       "      <td>see me pushin' through don't hate don't hate (...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1605 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "101     but this year i went down to miami and got my ...      0\n",
       "339     or a cop shot your kid in the back yard shit w...      0\n",
       "344     yo ernie c take these motherfuckers home yeah ...      0\n",
       "511     you gotta get your cash right to get in the ga...      0\n",
       "644     in the house boy i got my one and only afrika ...      0\n",
       "...                                                   ...    ...\n",
       "138192  i'm heavy in the hood 'cause i got that weight...      0\n",
       "138193  i'm heavy in the hood 'cause i got that weight...      0\n",
       "138194  (what up elder?) i'm heavy in the hood 'cause ...      0\n",
       "138196  (they already know they can't keep up with you...      0\n",
       "138197  see me pushin' through don't hate don't hate (...      0\n",
       "\n",
       "[1605 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_data_red = df_text_data[df_text_data['text'].str.contains('in the hood') | df_text_data['text'].str.contains('in the back') | df_text_data['text'].str.contains('in the house') | df_text_data['text'].str.contains('in the game')]\n",
    "df_text_data_red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace transformer is coming!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(df_text_data_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__'],\n",
       "    num_rows: 1605\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"i got respect cause his baby mama looks good (that's right) she rolling a blue s-class all up in the hood.\",\n",
       " 'label': 0,\n",
       " '__index_level_0__': 91221}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfa76c636ff4e2cac4ad24a8955b09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1605 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True, max_length=words_limit, return_tensors='pt')\n",
    "\n",
    "tokenized_datasets = hf_dataset.map(tokenize_function)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Item #0: in the middle of the night.\"I'm not sure what to do,\" he said. \"\n",
      " Item #1: in the middle of the night, and I was in the middle of the night, and I was in the\n",
      " Item #2: in the middle of the night.\"I'm not sure if I'm going to be able to\n",
      " Item #3: in the middle of the night.\"I'm not going to be able to sleep,\" he said\n",
      " Item #4: in the middle of the night.\"I'm not sure if I'm going to be able to\n",
      " Item #5: in the middle of the night, and I was like, 'Oh my God, I'm so sorry.'\n",
      " Item #6: in the middle of the night, and I was in the middle of the night, and I was in the\n",
      " Item #7: in the middle of the night, and I was like, 'Oh my God, I'm so sorry.\n",
      " Item #8: in the middle of the night, and I was in the middle of the night. I was in the middle\n",
      " Item #9: in the middle of the night, and I was just like, 'Oh my God, I can't believe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_start = \"in the\"\n",
    "cpu = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def generate_data(generation_start, model, tokenizer, num_return_sequences):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()    \n",
    "    model_cpu = model.to(cpu)\n",
    "    generator = pipeline('text-generation', model=model_cpu, tokenizer=tokenizer, temperature=0.1)\n",
    "    generated = generator(generation_start, max_length=words_limit, num_return_sequences=num_return_sequences)\n",
    "    for idx, item in enumerate(generated):\n",
    "        print(f' Item #{idx}:', item['generated_text'].strip().replace('\\n',''))\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return model\n",
    "    \n",
    "\n",
    "generate_data(generation_start, model, tokenizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"model_storage\")\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213c25ffc97848e69a645624e8162729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started. Eval on train: 17372.158203125. Cum norm: 9528.4931640625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385ac96d30f6456daa8567d238d4fc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 started. Eval on train: 17368.9609375. Cum norm: 9528.5244140625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcf507d20004783a4d0ee8e4f3501ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 started. Eval on train: 17369.955078125. Cum norm: 9528.5556640625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e075b61f59745eb9d3de5851f480312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 started. Eval on train: 17355.388671875. Cum norm: 9528.5869140625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e15088f29be4cce95307f7f9074faa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 started. Eval on train: 17227.53515625. Cum norm: 9528.6083984375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f152fa5c45d46c09888bd39237db640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 started. Eval on train: 17140.59765625. Cum norm: 9528.6318359375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ce7aff7a2043fb97c6a430a7f9b757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 started. Eval on train: 17208.685546875. Cum norm: 9528.66015625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1029c8518a245b9a1906c61573e0fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 started. Eval on train: 17265.462890625. Cum norm: 9528.685546875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a02f97b3e24baba20f1861fa081052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 started. Eval on train: 17303.18359375. Cum norm: 9528.701171875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f77f00c38b54510a7d8b60bbb5652f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 started. Eval on train: 17304.990234375. Cum norm: 9528.71484375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac16ece48024cad9813abf45b8104c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 started. Eval on train: 17326.810546875. Cum norm: 9528.7294921875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cfc7487dcf473aad7299f75c0d4403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 started. Eval on train: 17330.521484375. Cum norm: 9528.7431640625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c0e176c10447138c5ee5e841163d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 started. Eval on train: 17327.111328125. Cum norm: 9528.7529296875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abc74ab8cbc42a18e1e6bc8dfefb2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 started. Eval on train: 17326.25. Cum norm: 9528.7587890625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7936df63f1064dee80304ed910cf75b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 started. Eval on train: 17334.32421875. Cum norm: 9528.76953125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703ee517099b44e9982261cd819b1646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 started. Eval on train: 17332.431640625. Cum norm: 9528.775390625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d20d91b94c4ebb804fc70cdfa9fb92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 started. Eval on train: 17334.2578125. Cum norm: 9528.7802734375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe5a3bf49ad43bb8f90721313cfe0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 started. Eval on train: 17322.3125. Cum norm: 9528.78515625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4ccde7697142f8ac4fe19b483e4d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 started. Eval on train: 17335.82421875. Cum norm: 9528.7900390625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9255010ccb44c6bbc8eb9e3a1cb69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 started. Eval on train: 17322.447265625. Cum norm: 9528.79296875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e6495524f64a67be852d1fa22fa3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Item #0: in the the the the the the the the the the the the the the the the the the the the the\n",
      " Item #1: in the in in in in in in in in in in in in in in in in in in in in\n",
      " Item #2: in the in in in in in in in in in in in in in in in in in in in in\n",
      " Item #3: in the in in in in in in in in in in in in in in in in in in in in\n",
      " Item #4: in the in in in in in in in in in in in in in in in in in in in in\n",
      " Item #5: in the in in in in in in in in in in in in in in in in in in in in\n",
      " Item #6: in the in in in in in in in in in in in in in in in in in in in in\n",
      " Item #7: in the in in in in in in in in in in in in in in in in in in in in\n",
      " Item #8: in the in in in in in in in in in in in in in in in in in in in in\n",
      " Item #9: in the in in in in in in in in in in in in in in in in in in in in\n"
     ]
    }
   ],
   "source": [
    "trained_model = GPT2LMHeadModel.from_pretrained(\"model_storage\").to(device)\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def check_weights_cum_norm(model):\n",
    "    cum_norm = 0\n",
    "    for name, W in model.named_parameters():\n",
    "        cum_norm += W.norm(2)\n",
    "    return cum_norm\n",
    "\n",
    "def eval_on_loader(trained_model, loader):\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        for batch in train_dataloader:\n",
    "            ids = torch.stack(batch['input_ids'][0]).to(device)\n",
    "            outputs = trained_model(input_ids=ids)\n",
    "            logits = outputs['logits']\n",
    "            sentences = logits.transpose(0, 1)\n",
    "            labels = ids.transpose(0, 1)\n",
    "            \n",
    "            for sentence, label in zip(sentences, labels):\n",
    "                sentence_cloned = sentence.clone()\n",
    "                label_cloned = label.clone()\n",
    "                torch.nn.functional.relu(sentence_cloned, inplace=True)\n",
    "                losses.append(criterion(sentence_cloned, label_cloned))\n",
    "        return sum(losses)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(tokenized_datasets, shuffle=True, batch_size=batch_size)\n",
    "optimizer = AdamW(trained_model.parameters(), lr=0.000001)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.85)\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "num_epochs = 20\n",
    "progress_bar_epoch = tqdm(range(num_epochs))\n",
    "\n",
    "num_batches = len(tokenized_datasets) // batch_size\n",
    "if len(tokenized_datasets) % batch_size:\n",
    "    num_batches += 1\n",
    "gpt2_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = eval_on_loader(trained_model, train_dataloader)\n",
    "    print(f'Epoch {epoch} started. Eval on train: {train_loss}. Cum norm: {check_weights_cum_norm(trained_model)}')\n",
    "    gpt2_losses.append(train_loss.item())\n",
    "    progress_bar_batch = tqdm(range(num_batches))\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        ids = torch.stack(batch['input_ids'][0]).to(device)\n",
    "        outputs = trained_model(input_ids=ids)\n",
    "        logits = outputs['logits']\n",
    "        sentences = logits.transpose(0, 1)\n",
    "        labels = ids.transpose(0, 1)\n",
    "        losses = []\n",
    "        for sentence, label in zip(sentences, labels):\n",
    "            sentence_cloned = sentence.clone()\n",
    "            label_cloned = label.clone()\n",
    "            with torch.no_grad():\n",
    "                torch.nn.functional.relu(sentence_cloned, inplace=True)\n",
    "            losses.append(criterion(sentence_cloned, label_cloned))\n",
    "        \n",
    "        res_loss = sum(losses) / len(losses)\n",
    "        \n",
    "        res_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(trained_model.parameters(), 0.25)\n",
    "        optimizer.step()\n",
    "        progress_bar_batch.update(1)\n",
    "        del ids, outputs, logits, sentences, labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    progress_bar_epoch.update(1)\n",
    "    scheduler.step()\n",
    "trained_model = generate_data(generation_start, trained_model, tokenizer, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss for epoch')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(10, 6))\n",
    "metrics_df = pd.DataFrame({'Loss' : gpt2_losses, 'Epoch' : [idx for idx in range(num_epochs)]})\n",
    "axes.xaxis.set_major_formatter(FuncFormatter(lambda x, _: int(x)))\n",
    "sns.lineplot(data=metrics_df, y='Loss', x='Epoch', ax=axes)\n",
    "axes.set_title('Loss for epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trained_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Own RNN-based network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float32\n",
    "max_len = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(df_data):\n",
    "    vocab = set()\n",
    "    for line in df_data['text']:\n",
    "        words = wordpunct_tokenize(line)\n",
    "        for word in words:\n",
    "            if word.isdigit():\n",
    "                continue\n",
    "            word = ''.join(word.replace('\\'', ''))\n",
    "            if len(word) == 0:\n",
    "                continue\n",
    "            vocab.add(word)\n",
    "    return vocab\n",
    "\n",
    "class RnnTokenizer:\n",
    "    def __init__(self):\n",
    "        self.pad_word = '<pad>'\n",
    "        self.pad_token = 0\n",
    "    \n",
    "    def _enumerate_internal(self, vocab):\n",
    "        idx_shift = 1\n",
    "        return {word : idx + idx_shift for idx, word in enumerate(vocab)}\n",
    "    \n",
    "    def set_vocabulary(self, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.vocab.add(self.pad_word)\n",
    "        self.word_to_token = self._enumerate_internal(vocab)\n",
    "        self.word_to_token[self.pad_word] = self.pad_token\n",
    "        self.token_to_word = {v : k for k, v in self.word_to_token.items()}\n",
    "    \n",
    "    def encode(self, sentence, max_len):\n",
    "        words = wordpunct_tokenize(sentence)\n",
    "        encoded = []\n",
    "        idx = 0\n",
    "        while idx < max_len:\n",
    "            if idx >= len(words):\n",
    "                word = self.pad_word\n",
    "            else:\n",
    "                word = words[idx]\n",
    "            idx += 1\n",
    "            word = ''.join(word.replace('\\'', ''))\n",
    "            if len(word) == 0:\n",
    "                continue\n",
    "            if word.isdigit():\n",
    "                continue\n",
    "            encoded.append(self.word_to_token[word])\n",
    "        while len(encoded) < max_len:\n",
    "            encoded.append(self.pad_token)\n",
    "            idx += 1\n",
    "        return encoded\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        decoded = []\n",
    "        for token in tokens:\n",
    "            if token != self.pad_token:\n",
    "                decoded.append(self.token_to_word[token])\n",
    "        return ' '.join(decoded)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_rnngen = df_text_data_red\n",
    "vocab = get_vocabulary(df_for_rnngen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3346\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"but this year i went down to miami and got my nigga from 2 live brother marquis in the house! (yeah i'm.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_rnngen.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RnnTokenizer()\n",
    "tokenizer.set_vocabulary(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2753,\n",
       " 171,\n",
       " 29,\n",
       " 2759,\n",
       " 1532,\n",
       " 1398,\n",
       " 3217,\n",
       " 384,\n",
       " 1695,\n",
       " 3211,\n",
       " 527,\n",
       " 1287,\n",
       " 292,\n",
       " 824,\n",
       " 2286,\n",
       " 3073,\n",
       " 2241,\n",
       " 1576,\n",
       " 37,\n",
       " 2279,\n",
       " 1217,\n",
       " 1148,\n",
       " 2759,\n",
       " 3265,\n",
       " 122,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tokenizer.encode(df_for_rnngen.iloc[0].text, 50)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but this year i went down to miami and got my nigga from live brother marquis in the house ! ( yeah i m .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for line in df_for_rnngen['text']:\n",
    "    encoded = tokenizer.encode(line, max_len=max_len)\n",
    "    data_list.append(encoded)\n",
    "torch_dataset = torch.tensor(data_list, dtype=torch.long, device=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1715,  851, 2665,  924, 2475,  996, 2362, 1148, 1715,  725,  649, 2241,\n",
       "        1576,   37, 3192, 1355, 2883, 3045,  122,    0,    0,    0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's define NN arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnTextGenerator(nn.Module):\n",
    "    def __init__(self, tokenizer, device):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = 128\n",
    "        self.hidden_dim = 256\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(tokenizer.vocab)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            padding_idx=0\n",
    "        )\n",
    "        self.lstm = nn.LSTMCell(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.hidden_dim\n",
    "        )\n",
    "        self.fc1 = nn.Linear(self.hidden_dim, n_vocab // 2)\n",
    "        self.fc2 = nn.Linear(n_vocab // 2, n_vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "#         print('*', embed.shape)\n",
    "        transrosed_embed = embed.transpose(0, 1)\n",
    "        print('!', transrosed_embed.shape)\n",
    "        hx, cx = self._init_state(embed.shape[0])\n",
    "#         hx_storage = [hx]\n",
    "        for words_batch in transrosed_embed:\n",
    "#             print('words batch', words_batch.shape)\n",
    "#             print('hx', hx.shape)\n",
    "            hx, cx = self.lstm(words_batch, (hx, cx))\n",
    "#             hx_storage.append(hx)\n",
    "#         unpulled = torch.stack(hx_storage, dim=2)\n",
    "#         pooled = self.maxpool(backward_pass).view(-1, self.hidden_dim)\n",
    "        print('TO CHECK', )\n",
    "#         print('#', output.shape, state.shape)\n",
    "        output = self.fc1(hx)\n",
    "        logits = self.fc2(output)\n",
    "        print('LOGITS', logits.shape)\n",
    "        return logits\n",
    "\n",
    "    def _init_state(self, batch_size):\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, dtype=dtype, device=device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, dtype=dtype, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49 started.\n",
      "BATCH DATA torch.Size([16, 22])\n",
      "! torch.Size([22, 16, 128])\n",
      "TO CHECK\n",
      "LOGITS torch.Size([16, 3347])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_236702/1054864731.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BATCH DATA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/nlp-unn/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/nlp-unn/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1164\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m~/.anaconda3/envs/nlp-unn/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "epoch_count = 50\n",
    "rnn_model = RnnTextGenerator(tokenizer, device).to(device)\n",
    "optimizer = AdamW(rnn_model.parameters(), lr=0.000001)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.85)\n",
    "criterion = CrossEntropyLoss()\n",
    "batch_size = 16\n",
    "for epoch in range(epoch_count):\n",
    "    print(f'Epoch {epoch}/{epoch_count-1} started.')\n",
    "\n",
    "    # Train loop\n",
    "    perm_indices = list(BatchSampler(RandomSampler(range(torch_dataset.shape[0])), \n",
    "                                     batch_size=batch_size, drop_last=False))\n",
    "    for batch_idx, batch_indices in enumerate(perm_indices):\n",
    "        batch_data = torch_dataset[batch_indices].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        print('BATCH DATA', batch_data.shape)\n",
    "        predicted = rnn_model.forward(batch_data)\n",
    "        loss = criterion(predicted, batch_data)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 10)\n",
    "        optimizer.step()\n",
    "        del batch_data, batch_labels, batch_extra, predicted, loss\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
